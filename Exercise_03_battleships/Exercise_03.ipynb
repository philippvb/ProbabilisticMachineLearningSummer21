{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise #3: Battleships (2/2)\n",
    "\n",
    "### Probabilistic Machine Learning\n",
    "\n",
    "- **Lecturer**: Prof. Philipp Hennig\n",
    "- **Term**: SoSe 2020\n",
    "- **Due Date**: Monday, 11 May 2020\n",
    "\n",
    "\n",
    "<!-- ![battleship rules](https://upload.wikimedia.org/wikipedia/commons/e/e4/Battleships_Paper_Game.svg)-->\n",
    "\n",
    "In the previous exercise sheet on the game _battleships_, we studied prior and posterior probabilities of getting a hit by enumerating all possible locations of one boat. We established that it is computationally unfeasible to obtain the full posterior by enumeration for the number of ships in the rules.\n",
    "\n",
    "Hence, to render the problem tractable, we need to approximate the posterior over hits given hit/miss observations. We achieve this through _Monte Carlo_ sampling. Instead of enumerating _all_ board states, we randomly sample `nb_samples` valid board states (i.e. configurations of ship arrangements on the board) and use their sum to estimate the posterior.\n",
    "\n",
    "__The goal of this assignment is to write such a  Monte Carlo sampler.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __3.1__ Getting started\n",
    "\n",
    "There are a few accompanying files that are required for the game. You will only need to alter `MC_agent.py`, all other vital routines are provided.\n",
    "- `main.py`: Run this script to play the game. You can select which players should play against each other: `\"human\"`, `\"random\"`, or `\"MC\"`. The first two are already implemented, the latter is our task here.\n",
    "- `board.py`: contains a class to track the current state of the board (observations), and to save the placement of the ships.  \n",
    "- `game.py`: the game itself with relevant methods (initialize the game, calling the respective agents for their moves, checking if the game is over, etc.)\n",
    "- `human_agent.py`: The human agent (interactive input)\n",
    "- `random_agent.py`: The random agent (just selects a previously unobserved location at random)\n",
    "- `MC_Agent`: this is where you should implement the Monte Carlo Agent for the virtual opponent. Initially, it randomly selects a query location (i.e. you can play the game by running `main.py`, but the computer makes uninformed moves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the current state, you can already play the game against a random agent, or have two random agents play against each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # __3.2__ Implement the Monte Carlo Agent\n",
    "\n",
    "Your task is to replace the method `select_observation` in the class `MCAgent` by a routine that samples board states to estimate the posterior probability of getting a hit, and then choosing the location that maximizes this probability.\n",
    "\n",
    "The state of observations is saved in the variable `self.observed_board`. A `0` is an unobserved location, `-1` a miss or a sunk ship, and a `1` a hit of a ship that is not yet sunk.\n",
    "\n",
    "In `select_observation`, we first define a variable `score_board` through which we will assign scores to each field. Therefore it has the shape of the `self.observed_board`.\n",
    "\n",
    "_The key idea of the Monte Carlo agent is to sum up many possible boat placements and choose the location with the largest score (most boats placed) as new query location._\n",
    "\n",
    "Here is how to proceed (see comments in the function):\n",
    "1. Check if there is an \"open\" hit, i.e. a hit that does not belong to a sunk ship. If so, reduce the number of samples (e.g. to a tenth) and force possible boats to pass through the hit(s)\n",
    "2. In case there is no open hit, simulate `nb_samples` boats, the location and orientation of which are chosen at random. Track them using the `score_board`.\n",
    "3. Find the location with the largest score and return its indices.\n",
    "\n",
    "Once you're done, you can play against your agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_observation(self):\n",
    "    \"\"\"\n",
    "    --------------------------------------------------\n",
    "    THIS IS THE MONTE CARLO SAMPLER YOU NEED TO ADAPT.\n",
    "    --------------------------------------------------\n",
    "\n",
    "    Select the next location to be observed\n",
    "    :returns: i_new: int, j_new: int\n",
    "    \"\"\"\n",
    "\n",
    "    # New board to collect the states sampled by the MC agent\n",
    "    score_board = np.zeros_like(self.observed_board)\n",
    "    n_samples = self.nb_samples\n",
    "\n",
    "    #  +----------+\n",
    "    #  |  Task 1  |\n",
    "    #  +----------+\n",
    "    # Check if there is already an \"open\" hit, i.e. a ship that has been hit but not sunk\n",
    "    # These locations are handled by the observation_board as 1\n",
    "    # If there is already a hit, choose a random one to deal with next.\n",
    "    # Create a score board including that hit, and reduce the number of samples to 1/10\n",
    "    hit = None\n",
    "    if 1 in self.observed_board:\n",
    "        hits = np.where(self.observed_board == 1)\n",
    "        i = random.choice(range(len(hits[0])))\n",
    "        hit = (hits[0][i], hits[1][i])\n",
    "        n_samples /= 10\n",
    "\n",
    "    #  +----------+\n",
    "    #  |  Task 2  |\n",
    "    #  +----------+\n",
    "    # Populate the score_board with possible boat placements\n",
    "    i = 0\n",
    "    while i < n_samples:\n",
    "        board = np.zeros_like(self.observed_board)\n",
    "        for boat_size in self.remaining_ships:\n",
    "            while True:\n",
    "                o = random.choice(['h', 'v'])\n",
    "                x = random.choice(range(self.size - (boat_size - 1 if o == 'h' else 0)))\n",
    "                y = random.choice(range(self.size - (boat_size - 1 if o == 'v' else 0)))\n",
    "\n",
    "                d = np.hstack((np.zeros((boat_size, 1)), np.arange(boat_size)[:, None])[::(-1 if o == 'h' else 1)])\n",
    "                boat = tuple((np.array([[x, y]]) + d).astype(int).T)\n",
    "\n",
    "                # Place boats non-overlapping and not on misses or sunken ships.\n",
    "                if 1 in board[boat] or -1 in self.observed_board[boat]:\n",
    "                    continue\n",
    "\n",
    "                board[boat] = 1\n",
    "                break\n",
    "\n",
    "        # Sanity check\n",
    "        assert board.sum() == sum(self.remaining_ships)\n",
    "\n",
    "        if not hit or board[hit] == 1:\n",
    "            i += 1\n",
    "            score_board += board\n",
    "\n",
    "    #  +----------+\n",
    "    #  |  Task 3  |\n",
    "    #  +----------+\n",
    "    # Having populated the score board, select a new position by choosing the location with the highest score.\n",
    "    score_board *= np.where(self.observed_board == 1, 0, 1)\n",
    "    plt.imshow(score_board, cmap='hot')\n",
    "    plt.show()\n",
    "    time.sleep(1)\n",
    "    i_new, j_new = np.unravel_index(np.argmax(score_board), score_board.shape)\n",
    "\n",
    "    # return the next location to query, i_new: int, j_new: int\n",
    "    return i_new, j_new, score_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Player1's observations   Player2's observations\n",
      "\n",
      "  0 1 2 3 4 5 6 7 8 9      0 1 2 3 4 5 6 7 8 9\n",
      "0 - . X X - . . - . -    0 - - - . . - - - - .\n",
      "1 - . X - . - - . - .    1 . - X - . . - . . .\n",
      "2 . - X . - - . - . -    2 X - X - - - . - . .\n",
      "3 - . . - - . - . - .    3 X - . - . - . . . .\n",
      "4 X - . - . X - - . .    4 X . - . . . - - . .\n",
      "5 X . - . - X . - - .    5 X . - - - . - . - -\n",
      "6 X X . - . X - . - -    6 X . - - - - - . . .\n",
      "7 - . . X . X . - . .    7 - . - . . . - - . .\n",
      "8 - . - . - X . - - .    8 . . X . . X . . - -\n",
      "9 - - X X X X . - . -    9 - . . . - - . . . -\n",
      "Game over! Player 1 won!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from main import play_battleships\n",
    "%matplotlib inline\n",
    "play_battleships('MC', 'random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __3.2__ Further analysis\n",
    "__Task 1:__  \n",
    "Surface the score matrix (`score_board`) of your Monte Carlo agent and visualize it for each step of the game. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `select_observation` (imshow at the end)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2:__  \n",
    "How could you evaluate your agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Win / Loss ratio agains random agent; how many steps until win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 3:__  \n",
    "How could you improve your agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, the agent treats all hits separately. Actually, if there are hits like `--X-X--` and a length-three ship is missing, the obvious thing is to shoot between the two hits. The agent is not this smart (yet)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
